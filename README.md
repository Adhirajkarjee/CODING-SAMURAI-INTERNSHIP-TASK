# CODING-SAMURAI-DATA-SCIENCE-INTERNSHIP-TASK

## Projects Overview

### Level 1: Beginner (Basic Concepts and Skills)

#### 1. Simple Data Analytics - Sales Data Analysis
- Description: Analyzed a small dataset (sales data of a retail store) to understand basic concepts of data cleaning, descriptive statistics, and visualization. Visualizations include bar charts and pie charts to represent sales distribution.
- Tools Used: Python
  
#### 2. Linear Regression on Simple Dataset
- Description: Built a linear regression model to predict sales based on advertising spend.
- Skills Covered: Understanding of regression analysis, Python, Scikit-learn library for building and evaluating the model.

### Level 2: Intermediate (Slightly More Involved)

#### 3. Data Analytics - Exploratory Data Analysis (EDA) on Titanic Dataset
- Description: Performed exploratory data analysis (EDA) on the Titanic dataset to understand missing values, data distribution, and feature relationships. Used visualizations such as histograms and correlation heatmaps.
- Tools Used: Python, Seaborn, Matplotlib for visualizations and basic statistical analysis.

#### 4. Classification - Logistic Regression on the Titanic Dataset
- Description: Built a logistic regression model to predict survival on the Titanic based on passenger features such as age, sex, and class.
- Skills Covered: Classification techniques, feature engineering, and model evaluation using Python and Scikit-learn.

### Level 3: Advanced (Simplified)

#### 5. Time Series Forecasting for Stock Prices
- Description: Utilized historical stock price data to build a time series forecasting model, such as ARIMA or LSTM, to predict future stock prices.
- Skills Covered: Time series analysis, ARIMA and LSTM models, evaluation of forecast accuracy.

#### 6. Sentiment Analysis on Social Media Data
- Description: Collected social media data (e.g., tweets) and performed sentiment analysis to determine if the sentiment is positive, negative, or neutral.
- Tools Used: Natural Language Processing (NLP), sentiment analysis libraries such as NLTK or TextBlob, and data cleaning techniques.

## Requirements

- Python 3.x
- Required libraries:
  - pandas
  - numpy
  - scikit-learn
  - seaborn
  - matplotlib
  - nltk / textblob (for sentiment analysis)
  - statsmodels (for ARIMA)
  - tensorflow (for LSTM models)
